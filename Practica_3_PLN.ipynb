{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practica 3 PLN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5t4MXSOE2wXgrnXJHNkxP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielDes/PracticasPLN/blob/master/Practica_3_PLN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzH2oL-1DgBs",
        "colab_type": "text"
      },
      "source": [
        "# Practica 3 Procesamiento de Lenguaje Natural\n",
        "## De San Pedro Vázquez Luis Daniel\n",
        "\n",
        "Para la ejecución de este cuaderno en colab se recomienda cambiar el entorno de ejecucion con TPU para que los tiempos de entrenamiento sean considerablemente menores.\n",
        "\n",
        "Referencia al [ner_dataset](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus/home) usado en la práctica. Se debe subir al entorno de ejecución antes de ejecutar el cuaderno. O si se usa en un entorno local, el archivo debe estar presente en el mismo directorio del cuaderno."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9dCLLPjDXAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "# Frameworks usados para la preparacion del dataset\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "#Framework usados para la aquitectura de la red.\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Bidirectional\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6kOUr0znNUR",
        "colab_type": "text"
      },
      "source": [
        "## Preprocesamiento\n",
        "\n",
        "Se uso una version grande del ner_dataset que tiene las siegientes características. Por un lado para tener una mejor distribucion entre las porciones de entrenamiento, validación y testeo. Y por otro esta versión se volvió más fácil de arreglar con respecto a sus valores NaN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f-TS-IuDun6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "10195721-4ed9-4604-d512-ef258ad66608"
      },
      "source": [
        "data = pd.read_csv('ner_dataset.csv',encoding='ISO-8859-1')\n",
        "data = data.fillna(method = 'ffill')\n",
        "\n",
        "\n",
        "word_index= 0\n",
        "tag_index = 1\n",
        "\n",
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>47959</td>\n",
              "      <td>35178</td>\n",
              "      <td>42</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Sentence: 22480</td>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>104</td>\n",
              "      <td>52573</td>\n",
              "      <td>145807</td>\n",
              "      <td>887908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Sentence #     Word      POS      Tag\n",
              "count           1048575  1048575  1048575  1048575\n",
              "unique            47959    35178       42       17\n",
              "top     Sentence: 22480      the       NN        O\n",
              "freq                104    52573   145807   887908"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7Yw5amynGcf",
        "colab_type": "text"
      },
      "source": [
        "Observamos los tags que se encontraron en el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RMfEeuFISdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "cf564224-4b2d-4adf-a137-32ff4852ba72"
      },
      "source": [
        "data['Tag'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
              "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
              "       'I-eve', 'I-nat'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4EuOU7EnezT",
        "colab_type": "text"
      },
      "source": [
        "Agrupamos cada token y cada tag encontrado, ademas se añade un token padding que usaremos para rellenas las sentencias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06R0SgPxGu58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = list(data[\"Word\"].unique())\n",
        "tokens.append('<padding>')\n",
        "tags = list(data[\"Tag\"].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llvd2vb9oiFv",
        "colab_type": "text"
      },
      "source": [
        "Para cada sentencia agrupamos los tokens con sus respectivos tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqKICHgl4stA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped = data.groupby(\"Sentence #\")\n",
        "agg_func = lambda s: [[w,t] for w,t in zip(s[\"Word\"].values.tolist(),\n",
        "                                           s[\"Tag\"].values.tolist())]\n",
        "groups = grouped.apply(agg_func)\n",
        "\n",
        "corpus_sentences = [sentence for sentence in groups]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oOy5AHCo4dZ",
        "colab_type": "text"
      },
      "source": [
        "Creamos un diccionario para los tokens y para los tags, para obtener de manera más rápida y eficiente los índices de cada uno."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPzO-L4d853w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_index = {w : i for i, w in enumerate(tokens)}\n",
        "tag_to_index = {t : i for i, t in enumerate(tags)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VafVr2ippG8D",
        "colab_type": "text"
      },
      "source": [
        "Definimos hiperparámetros de la ejecucion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTFY_N5TJ9LO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hiperparámetros\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 3\n",
        "max_len = 90\n",
        "embedding = 40\n",
        "\n",
        "\n",
        "validation_portion = 0.1\n",
        "test_portion = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fNHx6WOpqKI",
        "colab_type": "text"
      },
      "source": [
        "Obtenemos el vector de entrada de la red, primero obteniendo para cada sentencia el índice de cada token. Luego rellenamos cada sentencia con el índice del token padding hasta que el tamaño del vector sea igual al que se definió en los hiperparámetros (max_len). Esto se tiene que hacer para que la dimension de entrada a la red sea concistente. También se debe mencionar que las entradas serán en batches de 32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqOyWVGjCp0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [[word_to_index[word[word_index]] for word in sentence] for sentence in corpus_sentences]\n",
        "\n",
        "X = pad_sequences(maxlen=max_len,sequences=X,padding=\"post\",value=word_to_index[\"<padding>\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfX1Q9LcqTa-",
        "colab_type": "text"
      },
      "source": [
        "Aplicamos el mismo tratamiento para el vector de salida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0wcjhU2LdzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = [[tag_to_index[word[tag_index]] for word in sentence] for sentence in corpus_sentences]\n",
        "\n",
        "y = pad_sequences(maxlen = max_len, sequences = y, padding = \"post\", value = tag_to_index[\"O\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GryNUWskqbwg",
        "colab_type": "text"
      },
      "source": [
        "Para el vector de salida, categorizamos para que tengamos una colección de one-hot vector que representa cada tag. Esto va ayudar cuando usemos entropía cruzada en la red."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6VK1t_PDqbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tags = data['Tag'].nunique()\n",
        "y = [to_categorical(i,num_classes = num_tags) for i in y] #Creamos un one-hot vector para y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZpqv9C9rb0z",
        "colab_type": "text"
      },
      "source": [
        "Dividimos los datos en un conjunto de entrenamiento y de testeo. Por el momento no es necesario hacer la división del conjunto de validación, ya que la red puede hacer esa reservación si lo indicamos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnubi6-aFsIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_portion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXCTdq--ruGL",
        "colab_type": "text"
      },
      "source": [
        "## Arquitectura de la red y entrenamiento\n",
        "\n",
        "La arquitectura de la red se compone primero de una capa de embedding, luego de una LSTM bidireccional, por para cada salida del LSTM se le aplica una capa densa, por ello se requiere usar del wrapper TimeDistributed.\n",
        "\n",
        "En la capa de embedding es importante mencionar que se aplica una máscara que marca todo dato que sea de padding, esto es muy importante, ya que esa máscara es usada por capas posteriores aparte de que indica a la hora de hacer la optimización que datos NO se deben de tomar en cuenta. También se debe mencionar, que en la capa de LSTM bidireccional se aplica un dropout de 0.1, esto para ayudar con problemas de overfitting.\n",
        "\n",
        "Usamos como optimizador \"adam\", que es un algoritmo de optimización basado en el de gradiente descendente estocástico donde el learning rate se va optimizando, y como función de riesgo la entropía cruzada.\n",
        "\n",
        "La salida de la red es un tensor, donse para cada token de cada sentencia, tenemos las probabilidades de cada tag para ese token. Por ello en la última capa se usa como activación \"softmax\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIWdgt3_IxfC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "9424f0b1-6b32-45f0-e5bf-ed87e44f011f"
      },
      "source": [
        "# Model architecture\n",
        "input = Input(shape = (max_len,))\n",
        "model = Embedding(input_dim = len(tokens),\n",
        "                  output_dim = embedding,\n",
        "                  input_length = max_len, \n",
        "                  mask_zero = True)(input)\n",
        "\n",
        "model = Bidirectional(LSTM(units = 50, \n",
        "                           return_sequences=True, \n",
        "                           recurrent_dropout=0.1))(model)\n",
        "\n",
        "out = TimeDistributed(Dense(num_tags, activation=\"softmax\"))(model)\n",
        "\n",
        "model = Model(input, out)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, 90, 40)            1407160   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 90, 100)           36400     \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 90, 17)            1717      \n",
            "=================================================================\n",
            "Total params: 1,445,277\n",
            "Trainable params: 1,445,277\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4qESXcxs1gx",
        "colab_type": "text"
      },
      "source": [
        "Al entrenar, le indicamos que del conjunto de entrenamiento se use la decima parte para validación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqsJHg2URGVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "3107e9f0-743f-4e2a-d4f1-719fcd03ef38"
      },
      "source": [
        "history = model.fit(X_train, np.array(y_train), batch_size=batch_size, epochs=epochs,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 30213 samples, validate on 3358 samples\n",
            "Epoch 1/3\n",
            "30213/30213 [==============================] - 145s 5ms/step - loss: 0.1677 - accuracy: 0.9672 - val_loss: 0.0673 - val_accuracy: 0.9822\n",
            "Epoch 2/3\n",
            "30213/30213 [==============================] - 142s 5ms/step - loss: 0.0423 - accuracy: 0.9884 - val_loss: 0.0359 - val_accuracy: 0.9895\n",
            "Epoch 3/3\n",
            "30213/30213 [==============================] - 144s 5ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.0320 - val_accuracy: 0.9904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pu3kqLQswjQ",
        "colab_type": "text"
      },
      "source": [
        "## Resultados\n",
        "\n",
        "Hacemos una evaluación de los resultados usando el conjunto de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XiGkQYAOTfP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "03294835-e2be-4e20-ac59-7c8d663de93e"
      },
      "source": [
        "results = model.evaluate(X_test,np.array(y_test),batch_size=batch_size)\n",
        "print(\"Test Data\\n Loss: {}\\n Accuracy: {}\".format(results[0],results[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14388/14388 [==============================] - 12s 855us/step\n",
            "Test Data\n",
            " Loss: 0.03067211702896848\n",
            " Accuracy: 0.9910122752189636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg4a_76vs_6W",
        "colab_type": "text"
      },
      "source": [
        "Por último mostramos algunas sentencias del conjunto de entrenamiento junto con las predicciones de cada token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0hEcVP6jcBm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b725993-ac6a-45eb-88b2-f8bda35c6f04"
      },
      "source": [
        "for test_index in range(5):\n",
        "  sent = ''.join([tokens[w] + \" \" if  tokens[w] != \"<padding>\" else '' for w in X_test[test_index]])\n",
        "  print(\"--------\\nSentence:\\n{}\\n\".format(sent))\n",
        "  predictions = model.predict(np.array([X_test[test_index]]))\n",
        "  max_pred = np.argmax(predictions, axis=-1)\n",
        "  for w,p,y in zip(X_test[test_index],max_pred[0],y_test[test_index]):\n",
        "    word = tokens[w]\n",
        "    if word == '<padding>':\n",
        "      continue\n",
        "    y_tag = np.argmax(y)\n",
        "    print(\"Token: {:14}\\t\\tPred_tg: {}\\t\\tTag: {}\".format(word,tags[p],tags[y_tag]))\n",
        "  print(\"-------\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------\n",
            "Sentence:\n",
            "In 1969 , an entire class of diplomats was sent to Vietnam . \n",
            "\n",
            "Token: In            \t\tPred_tg: O\t\tTag: O\n",
            "Token: 1969          \t\tPred_tg: B-tim\t\tTag: B-tim\n",
            "Token: ,             \t\tPred_tg: O\t\tTag: O\n",
            "Token: an            \t\tPred_tg: O\t\tTag: O\n",
            "Token: entire        \t\tPred_tg: O\t\tTag: O\n",
            "Token: class         \t\tPred_tg: O\t\tTag: O\n",
            "Token: of            \t\tPred_tg: O\t\tTag: O\n",
            "Token: diplomats     \t\tPred_tg: O\t\tTag: O\n",
            "Token: was           \t\tPred_tg: O\t\tTag: O\n",
            "Token: sent          \t\tPred_tg: O\t\tTag: O\n",
            "Token: to            \t\tPred_tg: O\t\tTag: O\n",
            "Token: Vietnam       \t\tPred_tg: B-geo\t\tTag: B-geo\n",
            "Token: .             \t\tPred_tg: O\t\tTag: O\n",
            "-------\n",
            "\n",
            "--------\n",
            "Sentence:\n",
            "The defendants appeared before London 's Old Bailey court Thursday via videolink from a high-security prison . \n",
            "\n",
            "Token: The           \t\tPred_tg: O\t\tTag: O\n",
            "Token: defendants    \t\tPred_tg: O\t\tTag: O\n",
            "Token: appeared      \t\tPred_tg: O\t\tTag: O\n",
            "Token: before        \t\tPred_tg: O\t\tTag: O\n",
            "Token: London        \t\tPred_tg: B-geo\t\tTag: B-geo\n",
            "Token: 's            \t\tPred_tg: O\t\tTag: O\n",
            "Token: Old           \t\tPred_tg: O\t\tTag: B-geo\n",
            "Token: Bailey        \t\tPred_tg: O\t\tTag: I-geo\n",
            "Token: court         \t\tPred_tg: O\t\tTag: O\n",
            "Token: Thursday      \t\tPred_tg: B-tim\t\tTag: B-tim\n",
            "Token: via           \t\tPred_tg: O\t\tTag: O\n",
            "Token: videolink     \t\tPred_tg: O\t\tTag: O\n",
            "Token: from          \t\tPred_tg: O\t\tTag: O\n",
            "Token: a             \t\tPred_tg: O\t\tTag: O\n",
            "Token: high-security \t\tPred_tg: O\t\tTag: O\n",
            "Token: prison        \t\tPred_tg: O\t\tTag: O\n",
            "Token: .             \t\tPred_tg: O\t\tTag: O\n",
            "-------\n",
            "\n",
            "--------\n",
            "Sentence:\n",
            "Egyptian forces placed metal barriers across several breaches in the Rafah border crossing Friday . \n",
            "\n",
            "Token: Egyptian      \t\tPred_tg: B-gpe\t\tTag: B-gpe\n",
            "Token: forces        \t\tPred_tg: O\t\tTag: O\n",
            "Token: placed        \t\tPred_tg: O\t\tTag: O\n",
            "Token: metal         \t\tPred_tg: O\t\tTag: O\n",
            "Token: barriers      \t\tPred_tg: O\t\tTag: O\n",
            "Token: across        \t\tPred_tg: O\t\tTag: O\n",
            "Token: several       \t\tPred_tg: O\t\tTag: O\n",
            "Token: breaches      \t\tPred_tg: O\t\tTag: O\n",
            "Token: in            \t\tPred_tg: O\t\tTag: O\n",
            "Token: the           \t\tPred_tg: O\t\tTag: O\n",
            "Token: Rafah         \t\tPred_tg: B-geo\t\tTag: B-geo\n",
            "Token: border        \t\tPred_tg: O\t\tTag: O\n",
            "Token: crossing      \t\tPred_tg: O\t\tTag: O\n",
            "Token: Friday        \t\tPred_tg: B-tim\t\tTag: B-tim\n",
            "Token: .             \t\tPred_tg: O\t\tTag: O\n",
            "-------\n",
            "\n",
            "--------\n",
            "Sentence:\n",
            "Aid agencies and governments are trying to help quake survivors before the harsh Himalayan winter sets in . \n",
            "\n",
            "Token: Aid           \t\tPred_tg: O\t\tTag: O\n",
            "Token: agencies      \t\tPred_tg: O\t\tTag: O\n",
            "Token: and           \t\tPred_tg: O\t\tTag: O\n",
            "Token: governments   \t\tPred_tg: O\t\tTag: O\n",
            "Token: are           \t\tPred_tg: O\t\tTag: O\n",
            "Token: trying        \t\tPred_tg: O\t\tTag: O\n",
            "Token: to            \t\tPred_tg: O\t\tTag: O\n",
            "Token: help          \t\tPred_tg: O\t\tTag: O\n",
            "Token: quake         \t\tPred_tg: O\t\tTag: O\n",
            "Token: survivors     \t\tPred_tg: O\t\tTag: O\n",
            "Token: before        \t\tPred_tg: O\t\tTag: O\n",
            "Token: the           \t\tPred_tg: O\t\tTag: O\n",
            "Token: harsh         \t\tPred_tg: O\t\tTag: O\n",
            "Token: Himalayan     \t\tPred_tg: B-geo\t\tTag: O\n",
            "Token: winter        \t\tPred_tg: O\t\tTag: O\n",
            "Token: sets          \t\tPred_tg: O\t\tTag: O\n",
            "Token: in            \t\tPred_tg: O\t\tTag: O\n",
            "Token: .             \t\tPred_tg: O\t\tTag: O\n",
            "-------\n",
            "\n",
            "--------\n",
            "Sentence:\n",
            "The DRC is struggling to emerge from decades of political instability and violence . \n",
            "\n",
            "Token: The           \t\tPred_tg: O\t\tTag: O\n",
            "Token: DRC           \t\tPred_tg: B-org\t\tTag: B-org\n",
            "Token: is            \t\tPred_tg: O\t\tTag: O\n",
            "Token: struggling    \t\tPred_tg: O\t\tTag: O\n",
            "Token: to            \t\tPred_tg: O\t\tTag: O\n",
            "Token: emerge        \t\tPred_tg: O\t\tTag: O\n",
            "Token: from          \t\tPred_tg: O\t\tTag: O\n",
            "Token: decades       \t\tPred_tg: O\t\tTag: O\n",
            "Token: of            \t\tPred_tg: O\t\tTag: O\n",
            "Token: political     \t\tPred_tg: O\t\tTag: O\n",
            "Token: instability   \t\tPred_tg: O\t\tTag: O\n",
            "Token: and           \t\tPred_tg: O\t\tTag: O\n",
            "Token: violence      \t\tPred_tg: O\t\tTag: O\n",
            "Token: .             \t\tPred_tg: O\t\tTag: O\n",
            "-------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e28vk8rpubzI",
        "colab_type": "text"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "Podemos observar que los resultados son bastante buenos. Con los parámetros que se definieron, no se requiere de muchas épocas para tener un buen desempeño.\n",
        "\n",
        "A pesar de que las presiciones en el entrenamiento y en el testeo sean similares, nos da señal de que no hay un caso de overfitting. Sin embargo no significa que la red sea completamente infalible, el corpus usado es todavía una pequeña parte de todo lo que está en el mundo real."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhwIJlRzvff-",
        "colab_type": "text"
      },
      "source": [
        "## Referencias\n",
        "\n",
        "\n",
        "https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
        "\n",
        "https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/\n",
        "\n",
        "https://www.tensorflow.org/guide/keras/masking_and_padding\n",
        "\n",
        "https://www.tensorflow.org/guide/keras/rnn"
      ]
    }
  ]
}